{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c98e59-8d83-418b-ac11-2ffd5db19cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7c372a-2c47-45ef-841d-961ae372c75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68877072-44f0-48c3-a0bf-2deb31756705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete Training Script for Facial Emotion Recognition using ResNet-18\n",
    "7 emotions: angry, disgust, fear, happy, sad, surprise, neutral\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet18, ResNet18_Weights   #added\n",
    "\n",
    "CLASS_NAMES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# Paths - MODIFY THESE\n",
    "TRAIN_DIR = Path(r\"C:\\Users\\Dr_AI.TWR\\fer2013Prototype\\emotion_pipeline\\archive\\train\")  # Directory with 7 emotion folders\n",
    "TEST_DIR = Path(r\"C:\\Users\\Dr_AI.TWR\\fer2013Prototype\\emotion_pipeline\\archive\\test\")     # Directory with 7 emotion folders\n",
    "\n",
    "#Ensure paths exist\n",
    "assert TRAIN_DIR.exists(), f\"TRAIN_DIR not found: {TRAIN_DIR}\"\n",
    "assert TEST_DIR.exists(), f\"TEST_DIR not found: {TEST_DIR}\"\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "VAL_SPLIT = 0.2\n",
    "NUM_WORKERS = 0            #set to 0 if you get issues on Windows\n",
    "PATIENCE = 7  # For early stopping\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7eaeb8-bb05-48c0-a576-a2d479e8ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Dataset for emotion images organized in folders by class\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69c130c-4a9c-4b8a-8610-339278ebb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_emotion_data(data_dir, val_split=0.2, random_state=42):\n",
    "    \"\"\"Load images from folder structure and create train/val split\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for emotion_name in CLASS_NAMES:\n",
    "        emotion_dir = data_dir / emotion_name\n",
    "        \n",
    "        if not emotion_dir.exists():\n",
    "            print(f\"Warning: Folder '{emotion_name}' not found in {data_dir}\")\n",
    "            continue\n",
    "        \n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif']:\n",
    "            image_files.extend(list(emotion_dir.glob(ext)))\n",
    "        \n",
    "        label_idx = CLASS_TO_IDX[emotion_name]\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            all_paths.append(str(img_path))\n",
    "            all_labels.append(label_idx)\n",
    "        \n",
    "        print(f\"Found {len(image_files)} images for '{emotion_name}'\")\n",
    "    \n",
    "    print(f\"Total images: {len(all_paths)}\")\n",
    "    \n",
    "    if val_split > 0:\n",
    "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "            all_paths, all_labels,\n",
    "            test_size=val_split,\n",
    "            random_state=random_state,\n",
    "            stratify=all_labels\n",
    "        )\n",
    "        print(f\"Train images: {len(train_paths)}\")\n",
    "        print(f\"Validation images: {len(val_paths)}\")\n",
    "        return train_paths, train_labels, val_paths, val_labels\n",
    "    else:\n",
    "        return all_paths, all_labels, [], []\n",
    "\n",
    "\n",
    "def get_data_loaders(train_dir, test_dir, batch_size=32, val_split=0.2, num_workers=0):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    IMG_SIZE = 224\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # No augmentation for validation/test\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    #Load training data (includes validataion data)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOADING TRAINING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    train_paths, train_labels, val_paths, val_labels = load_emotion_data(            #no random state?\n",
    "        train_dir, val_split=val_split\n",
    "    )\n",
    "\n",
    "    #Load test data\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LOADING TEST DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    test_paths, test_labels, _, _ = load_emotion_data(test_dir, val_split=0.0)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = EmotionDataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = EmotionDataset(val_paths, val_labels, transform=val_test_transform)\n",
    "    test_dataset = EmotionDataset(test_paths, test_labels, transform=val_test_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(                                   #DataLoader function defined in PyTorch. Returns images, labels in n=batchsize batches\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0,                  #force single-process\n",
    "        pin_memory=False               # - no pinned memory on CPU only\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358e02ad-5be8-4b72-8982-8e64c8a8cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL CREATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_resnet18_model(num_classes=7, pretrained=True):\n",
    "    \"\"\"Create ResNet-18 for emotion classification\"\"\"\n",
    "    \n",
    "    # Load pretrained weights or None\n",
    "    weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = resnet18(weights=weights)\n",
    "    \n",
    "    # Replace the classifier head with dropout + linear layer\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.3),                                        #randomly deactivates a subset of neurons during training to reduce overfitting (increase to 0.5?)\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    #Unfreeze entire backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True   \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785ca5c6-c17b-4384-8ed2-fe861fa1d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):     #criterion = the loss function (e.g. nn.CrossEntropyLoss)\n",
    "    \"\"\"Train for one epoch\"\"\"                                               #optimizer updates the model's parameters (torch.optim.Adam or SGD)\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')         #pbar = progress bar -- for visualization\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)    #Moves tensors to GPU or CPU\n",
    "        \n",
    "        optimizer.zero_grad()                          #Before computing gradients for this batch, we reset previous gradients to zero.\n",
    "        \n",
    "        outputs = model(images)                         #feeds batch of images throught the network. Outputs tensor of shape (batch_size, num_classes),\n",
    "                                                        #   each row containing raw logits (unnormalized scores) for each class\n",
    "        loss = criterion(outputs, labels)               #Computes loss, returns scalar loss (average over the batch)\n",
    "        loss.backward()                                 #Back propagation\n",
    "        optimizer.step()                                #Uses the gradients to update the model's parameters (adjusts weights to reduce loss)\n",
    "        \n",
    "        # Update loss\n",
    "        running_loss += loss.item()                    #loss.item() converts the PyTorch scalar tensor to a Python float.\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update accuracy\n",
    "        _, predicted = outputs.max(1)                   #predicted gets the index of the maximum (argmax), i.e., the predicted class ID.\n",
    "        total += labels.size(0)                         #We increase total to track how many samples we've seen so far in the epoch.\n",
    "        correct += predicted.eq(labels).sum().item()    #correct = total number of correctly classified samples\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss / num_batches,\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / num_batches            #computes mean loss per batch\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc                       #Scalars: epoch_loss: average training loss for this epoch.\n",
    "                                                       #         epoch_acc: average training accuracy (percent).\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()                                       #Puts model in evaluation mode (turns off Dropout and uses running means instaed of batch stats)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():                                           #Pytorch does not compute gradients (optimizes performance & memory), avoids backdrop storage overhead\n",
    "        for images, labels in tqdm(val_loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                scheduler, device, num_epochs=50, patience=7):\n",
    "    \"\"\"Main training loop with early stopping\"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)                              \n",
    "        current_lr = optimizer.param_groups[0]['lr']          #grabs current learning rate from optimizer to print it\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'✓ New best model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'No improvement. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\n⚠ Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)      \n",
    "\n",
    "    \n",
    "    return model, best_val_acc                                                   #returns model:FIXME current model(wights from last epoch trained, \n",
    "                                                                                #   not necessarily the best. (OK?--YES) and returns best validation acc encountered \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805c9761-01ed-40b6-81a3-00742256c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax1.plot(train_losses, label='Train Loss', marker='o')\n",
    "    ax1.plot(val_losses, label='Val Loss', marker='s')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax2.plot(train_accs, label='Train Acc', marker='o')\n",
    "    ax2.plot(val_accs, label='Val Acc', marker='s')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n✓ Training history plot saved as 'training_history.png'\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Confusion matrix saved as 'confusion_matrix.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56d0780-266a-4170-9bb1-0812a8463145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    \"\"\"Evaluate model on test set and plot confusion matrix.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            # Accumulate predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Accuracy update\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_acc = 100.0 * correct / total\n",
    "    print(f\"\\n✓ Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "    \n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff14e246-5c7b-4473-820a-f4710f65dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to define main()\n",
      "About to call main() explicitly\n",
      "\n",
      "============================================================\n",
      "FACIAL EMOTION RECOGNITION - ResNet18\n",
      "============================================================\n",
      "Device: cuda\n",
      "Batch Size: 32\n",
      "Learning Rate: 0.001\n",
      "Number of Epochs: 50\n",
      "Validation Split: 0.2\n",
      "============================================================\n",
      "============================================================\n",
      "LOADING TRAINING DATA\n",
      "============================================================\n",
      "Found 3995 images for 'angry'\n",
      "Found 436 images for 'disgust'\n",
      "Found 4097 images for 'fear'\n",
      "Found 7215 images for 'happy'\n",
      "Found 4965 images for 'neutral'\n",
      "Found 4830 images for 'sad'\n",
      "Found 3171 images for 'surprise'\n",
      "Total images: 28709\n",
      "Train images: 22967\n",
      "Validation images: 5742\n",
      "\n",
      "============================================================\n",
      "LOADING TEST DATA\n",
      "============================================================\n",
      "Found 958 images for 'angry'\n",
      "Found 111 images for 'disgust'\n",
      "Found 1024 images for 'fear'\n",
      "Found 1774 images for 'happy'\n",
      "Found 1233 images for 'neutral'\n",
      "Found 1247 images for 'sad'\n",
      "Found 831 images for 'surprise'\n",
      "Total images: 7178\n",
      "\n",
      "Data loaders ready:\n",
      "  Train batches: 718\n",
      "  Val batches: 180\n",
      "  Test batches: 225\n",
      "One batch: torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
      "\n",
      "============================================================\n",
      "INITIALIZING MODEL\n",
      "============================================================\n",
      "✓ ResNet-18 model created (pretrained on ImageNet)\n",
      "✓ Final layer modified for 7 classes\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Epoch 1/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████| 718/718 [01:43<00:00,  6.93it/s, loss=1.34, acc=49.2]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3413, Train Acc: 49.24%\n",
      "Val Loss: 1.2602, Val Acc: 49.88%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 49.88%)\n",
      "\n",
      "Epoch 2/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.45it/s, loss=1.16, acc=56.8]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1576, Train Acc: 56.79%\n",
      "Val Loss: 1.0896, Val Acc: 57.84%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 57.84%)\n",
      "\n",
      "Epoch 3/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████| 718/718 [01:39<00:00,  7.18it/s, loss=1.08, acc=59.7]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0797, Train Acc: 59.69%\n",
      "Val Loss: 1.0599, Val Acc: 60.59%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 60.59%)\n",
      "\n",
      "Epoch 4/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.51it/s, loss=1.03, acc=61.8]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0296, Train Acc: 61.82%\n",
      "Val Loss: 1.0258, Val Acc: 60.12%\n",
      "Learning Rate: 0.001000\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 5/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:48<00:00,  6.64it/s, loss=0.979, acc=63.5]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9792, Train Acc: 63.49%\n",
      "Val Loss: 0.9931, Val Acc: 62.43%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 62.43%)\n",
      "\n",
      "Epoch 6/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.47it/s, loss=0.944, acc=64.7]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9439, Train Acc: 64.67%\n",
      "Val Loss: 0.9921, Val Acc: 63.17%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 63.17%)\n",
      "\n",
      "Epoch 7/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.46it/s, loss=0.896, acc=66.4]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8964, Train Acc: 66.42%\n",
      "Val Loss: 0.9866, Val Acc: 64.16%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 64.16%)\n",
      "\n",
      "Epoch 8/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:37<00:00,  7.40it/s, loss=0.858, acc=68.2]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8584, Train Acc: 68.19%\n",
      "Val Loss: 0.9812, Val Acc: 63.76%\n",
      "Learning Rate: 0.001000\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 9/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.53it/s, loss=0.811, acc=69.7]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8111, Train Acc: 69.70%\n",
      "Val Loss: 0.9728, Val Acc: 64.79%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 64.79%)\n",
      "\n",
      "Epoch 10/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.47it/s, loss=0.769, acc=71.8]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7686, Train Acc: 71.84%\n",
      "Val Loss: 0.9935, Val Acc: 64.79%\n",
      "Learning Rate: 0.001000\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 11/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.48it/s, loss=0.716, acc=73.3]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7159, Train Acc: 73.31%\n",
      "Val Loss: 1.0144, Val Acc: 64.75%\n",
      "Learning Rate: 0.001000\n",
      "No improvement. Patience: 2/7\n",
      "\n",
      "Epoch 12/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.46it/s, loss=0.663, acc=75.4]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6634, Train Acc: 75.42%\n",
      "Val Loss: 1.0083, Val Acc: 65.13%\n",
      "Learning Rate: 0.001000\n",
      "✓ New best model saved! (Val Acc: 65.13%)\n",
      "\n",
      "Epoch 13/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.47it/s, loss=0.618, acc=77.5]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6176, Train Acc: 77.45%\n",
      "Val Loss: 1.0421, Val Acc: 64.79%\n",
      "Learning Rate: 0.000500\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 14/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.46it/s, loss=0.461, acc=83.3]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4608, Train Acc: 83.28%\n",
      "Val Loss: 1.0997, Val Acc: 65.87%\n",
      "Learning Rate: 0.000500\n",
      "✓ New best model saved! (Val Acc: 65.87%)\n",
      "\n",
      "Epoch 15/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.47it/s, loss=0.38, acc=86.2]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3800, Train Acc: 86.21%\n",
      "Val Loss: 1.1643, Val Acc: 67.35%\n",
      "Learning Rate: 0.000500\n",
      "✓ New best model saved! (Val Acc: 67.35%)\n",
      "\n",
      "Epoch 16/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:36<00:00,  7.45it/s, loss=0.334, acc=87.9]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3339, Train Acc: 87.86%\n",
      "Val Loss: 1.2731, Val Acc: 66.60%\n",
      "Learning Rate: 0.000500\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 17/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.49it/s, loss=0.291, acc=89.7]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2909, Train Acc: 89.65%\n",
      "Val Loss: 1.3786, Val Acc: 65.69%\n",
      "Learning Rate: 0.000250\n",
      "No improvement. Patience: 2/7\n",
      "\n",
      "Epoch 18/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:34<00:00,  7.60it/s, loss=0.215, acc=92.7]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2153, Train Acc: 92.65%\n",
      "Val Loss: 1.4128, Val Acc: 66.39%\n",
      "Learning Rate: 0.000250\n",
      "No improvement. Patience: 3/7\n",
      "\n",
      "Epoch 19/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.54it/s, loss=0.178, acc=93.9]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1778, Train Acc: 93.95%\n",
      "Val Loss: 1.4700, Val Acc: 66.48%\n",
      "Learning Rate: 0.000250\n",
      "No improvement. Patience: 4/7\n",
      "\n",
      "Epoch 20/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.52it/s, loss=0.15, acc=95]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1496, Train Acc: 94.99%\n",
      "Val Loss: 1.5434, Val Acc: 67.08%\n",
      "Learning Rate: 0.000250\n",
      "No improvement. Patience: 5/7\n",
      "\n",
      "Epoch 21/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:35<00:00,  7.51it/s, loss=0.137, acc=95.5]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:12<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1370, Train Acc: 95.51%\n",
      "Val Loss: 1.6240, Val Acc: 67.22%\n",
      "Learning Rate: 0.000125\n",
      "No improvement. Patience: 6/7\n",
      "\n",
      "Epoch 22/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████| 718/718 [01:29<00:00,  8.04it/s, loss=0.102, acc=96.5]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:12<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1025, Train Acc: 96.53%\n",
      "Val Loss: 1.6491, Val Acc: 67.76%\n",
      "Learning Rate: 0.000125\n",
      "✓ New best model saved! (Val Acc: 67.76%)\n",
      "\n",
      "Epoch 23/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:29<00:00,  8.01it/s, loss=0.0899, acc=97.1]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:11<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0899, Train Acc: 97.07%\n",
      "Val Loss: 1.7295, Val Acc: 67.15%\n",
      "Learning Rate: 0.000125\n",
      "No improvement. Patience: 1/7\n",
      "\n",
      "Epoch 24/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:38<00:00,  7.26it/s, loss=0.0823, acc=97.2]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:13<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0823, Train Acc: 97.18%\n",
      "Val Loss: 1.7632, Val Acc: 67.15%\n",
      "Learning Rate: 0.000125\n",
      "No improvement. Patience: 2/7\n",
      "\n",
      "Epoch 25/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:34<00:00,  7.57it/s, loss=0.0751, acc=97.6]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:12<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0751, Train Acc: 97.64%\n",
      "Val Loss: 1.8229, Val Acc: 66.93%\n",
      "Learning Rate: 0.000063\n",
      "No improvement. Patience: 3/7\n",
      "\n",
      "Epoch 26/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:29<00:00,  7.99it/s, loss=0.0631, acc=97.9]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:10<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0631, Train Acc: 97.94%\n",
      "Val Loss: 1.8351, Val Acc: 67.73%\n",
      "Learning Rate: 0.000063\n",
      "No improvement. Patience: 4/7\n",
      "\n",
      "Epoch 27/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:26<00:00,  8.32it/s, loss=0.0532, acc=98.2]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:11<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0532, Train Acc: 98.25%\n",
      "Val Loss: 1.8938, Val Acc: 67.42%\n",
      "Learning Rate: 0.000063\n",
      "No improvement. Patience: 5/7\n",
      "\n",
      "Epoch 28/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:24<00:00,  8.48it/s, loss=0.0504, acc=98.4]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:10<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0504, Train Acc: 98.37%\n",
      "Val Loss: 1.9625, Val Acc: 67.71%\n",
      "Learning Rate: 0.000063\n",
      "No improvement. Patience: 6/7\n",
      "\n",
      "Epoch 29/50\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████| 718/718 [01:24<00:00,  8.54it/s, loss=0.0501, acc=98.4]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 180/180 [00:10<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0501, Train Acc: 98.42%\n",
      "Val Loss: 1.9662, Val Acc: 67.29%\n",
      "Learning Rate: 0.000031\n",
      "No improvement. Patience: 7/7\n",
      "\n",
      "⚠ Early stopping triggered at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr_AI.TWR\\AppData\\Local\\Temp\\ipykernel_1184\\1463428481.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('best_model.pth', map_location=DEVICE)        #ensures always load to correct device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training history plot saved as 'training_history.png'\n",
      "\n",
      "============================================================\n",
      "LOADING BEST MODEL FOR TESTING\n",
      "============================================================\n",
      "✓ Loaded best model (Val Acc: 67.76%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|███████████████████████████████████████████████████████████████████████| 225/225 [00:15<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Test Accuracy: 67.16%\n",
      "✓ Confusion matrix saved as 'confusion_matrix.png'\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE - SUMMARY\n",
      "============================================================\n",
      "Best Validation Accuracy: 67.76%\n",
      "Test Accuracy: 67.16%\n",
      "Model saved as: best_model.pth\n",
      "============================================================\n",
      "returned from main\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"About to define main()\")\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FACIAL EMOTION RECOGNITION - ResNet18\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "    print(f\"Number of Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"Validation Split: {VAL_SPLIT}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Load data\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        val_split=VAL_SPLIT,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData loaders ready:\")\n",
    "    print(f\"  Train batches: {len(train_loader)}\")\n",
    "    print(f\"  Val batches: {len(val_loader)}\")\n",
    "    print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "    #for debugging\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(\"One batch:\", images.shape, labels.shape)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"INITIALIZING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    model = create_resnet18_model(num_classes=len(CLASS_NAMES), pretrained=True)\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"✓ ResNet-18 model created (pretrained on ImageNet)\")\n",
    "    print(f\"✓ Final layer modified for {len(CLASS_NAMES)} classes\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=3, factor=0.5\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model, best_val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, \n",
    "        optimizer, scheduler, DEVICE, \n",
    "        num_epochs=NUM_EPOCHS, patience=PATIENCE\n",
    "    )\n",
    "    \n",
    "    # Load best model for testing\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LOADING BEST MODEL FOR TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    state_dict = torch.load('best_model.pth', map_location=DEVICE)        #ensures always load to correct device\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)                                                      #not necessary, ensures model is loaded to proper device\n",
    "    print(f\"✓ Loaded best model (Val Acc: {best_val_acc:.2f}%)\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_acc = evaluate_model(model, test_loader, DEVICE, CLASS_NAMES)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Model saved as: best_model.pth\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print(\"About to call main() explicitly\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "main()\n",
    "print(\"returned from main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427c85f-12a2-42f6-a143-a89bea904243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emotion_pipeline)",
   "language": "python",
   "name": "emotion-pipeline-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
