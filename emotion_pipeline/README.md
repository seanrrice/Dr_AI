# ðŸ“˜ Emotion Analysis Pipeline  
**(ResNet-34 / ResNet-18 + MediaPipe + Visit Logging)**

This directory contains the **facial emotion recognition subsystem** of the *Doctor AI* project.

The subsystem supports **multiple emotion-model pipelines**, real-time inference, structured visit logging, and longitudinal affect analysis.

---

# ðŸ“‚ Project Structure (Current)

emotion_pipeline/
â”‚
â”œâ”€â”€ .venv311/ # Runtime environment (CPU / inference)
â”œâ”€â”€ .venv_gpu/ # Training environment (GPU / CUDA)
â”‚
â”œâ”€â”€ analysis/
â”‚ â””â”€â”€ emotion_trend_analysis.ipynb
â”‚
â”œâ”€â”€ emotion_logs/ # Auto-generated visit emotion CSVs
â”‚
â”œâ”€â”€ master_dataset/ # Unified, curated dataset (non-FER2013)
â”‚
â”œâ”€â”€ matlockDatasetPipeline.ipynb # ResNet-34 training on master_dataset
â”œâ”€â”€ fer2013_v2.ipynb # ResNet-18 training on FER-2013
â”‚
â”œâ”€â”€ webcam_emotion_mediapipe.py # Real-time inference + visit logging
â”œâ”€â”€ emotion_logger.py # Patient-aware CSV logging utility
â”‚
â”œâ”€â”€ best_model.pth
â”œâ”€â”€ confusion_matrix.png
â”œâ”€â”€ training_history.png
â”‚
â”œâ”€â”€ requirements-train.txt
â”œâ”€â”€ requirements-runtime.txt
â””â”€â”€ README.md


---

# ðŸ”§ Environment Setup

Two **separate virtual environments** are used to isolate training and runtime concerns.

> âš ï¸ Virtual environments and Jupyter kernels are **path-dependent**.  
> If this directory is renamed or moved, reinstall Jupyter and re-register kernels.

---

## ðŸ§  Training Environment (GPU)

Used for **all model training and dataset pipelines**.

```powershell
python -m venv .venv_gpu
.\.venv_gpu\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements-train.txt
(Optional) Register kernel:

python -m ipykernel install --user --name emotion_train --display-name "Python (emotion_train)"
ðŸŽ¥ Runtime Environment (Inference)
Used for webcam inference, logging, and analysis.

python -m venv .venv311
.\.venv311\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements-runtime.txt
Register kernel:

python -m ipykernel install --user --name emotion_runtime --display-name "Python (emotion_runtime)"
Launch Jupyter safely:

python -m notebook
ðŸ§  Model Training Pipelines
This repository contains two independent training pipelines, serving different experimental and deployment goals.

ðŸ”¬ Pipeline 1 â€” Master Dataset + ResNet-34
matlockDatasetPipeline.ipynb

Primary research and deployment pipeline.

Uses a custom curated dataset:

master_dataset/
Trains a ResNet-34 backbone

Higher model capacity and generalization

Intended for final Doctor AI deployment models

Responsibilities:

Dataset preprocessing and splits

ResNet-34 model definition

Training and evaluation

Confusion matrix + metrics

Saving trained weights (best_model.pth)

ðŸ§ª Pipeline 2 â€” FER-2013 + ResNet-18
fer2013_v2.ipynb

Secondary / comparative pipeline.

Uses the FER-2013 dataset

Trains a ResNet-18 backbone

Lightweight and fast to train

Used for benchmarking, ablation studies, and reproducibility

Dataset location:

fer2013_dataset/
This pipeline is not deprecated and remains useful for controlled experiments.

ðŸŽ¥ Real-Time Emotion Detection
webcam_emotion_mediapipe.py

Performs real-time facial emotion recognition using:

MediaPipe face detection

A trained ResNet model (from either pipeline)

OpenCV webcam capture

Torch inference

Structured per-visit emotion logging

Run:

python webcam_emotion_mediapipe.py
The model path can be swapped to evaluate ResNet-18 vs ResNet-34.

ðŸ§¾ Emotion Visit Logging
emotion_logger.py

Provides:

Automatic creation of emotion_logs/

Visit-level aggregation

Emotion counts and percentages

Patient and visit metadata

Example:

logger = EmotionVisitLogger(
    emotion_labels=['angry','disgust','fear','happy','sad'],
    metadata_fields=['patient_id', 'visit_label']
)

logger.log_visit(
    emotion_counts,
    total_samples,
    meta={"patient_id": pid, "visit_label": label}
)
ðŸ“Š Longitudinal Trend Analysis
analysis/emotion_trend_analysis.ipynb

Supports:

End-of-visit summaries

Emotion percentage trajectories across visits

Dominant emotion analysis

Patient-level filtering

Chronological visit indexing

ðŸ“Œ Notebook assumes it is launched from the project root.

ðŸ“¦ Requirements Files
File	Purpose
requirements-train.txt	GPU training, PyTorch, torchvision, matplotlib
requirements-runtime.txt	MediaPipe, OpenCV, lightweight inference
ðŸ§¼ Notes & Best Practices
.venv311/, .venv_gpu/, master_dataset/, and emotion_logs/ should be gitignored

Always launch Jupyter with:

python -m notebook
Two pipelines â‰  duplication â€” they serve different scientific purposes

Prefer relative paths anchored to project root


---

## âœ… Option 2: Create it from PowerShell (no editor needed)

From the repo root:
```powershell
notepad README.md
