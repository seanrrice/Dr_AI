{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c98e59-8d83-418b-ac11-2ffd5db19cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68877072-44f0-48c3-a0bf-2deb31756705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete Training Script for Facial Emotion Recognition using ResNet-18\n",
    "7 emotions: angry, disgust, fear, happy, sad, surprise, neutral\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet18, ResNet18_Weights   #added\n",
    "\n",
    "CLASS_NAMES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# Paths - MODIFY THESE\n",
    "TRAIN_DIR = Path(r\"C:\\Users\\seanr\\fer2013Prototype\\data\\fer2013_folders\\train\")  # Directory with 7 emotion folders\n",
    "TEST_DIR = Path(r\"C:\\Users\\seanr\\fer2013Prototype\\data\\fer2013_folders\\test\")     # Directory with 7 emotion folders\n",
    "\n",
    "#Ensure paths exist\n",
    "assert TRAIN_DIR.exists(), f\"TRAIN_DIR not found: {TRAIN_DIR}\"\n",
    "assert TEST_DIR.exists(), f\"TEST_DIR not found: {TEST_DIR}\"\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "VAL_SPLIT = 0.2\n",
    "NUM_WORKERS = 4            #set to 0 if you get issues on Windows\n",
    "PATIENCE = 7  # For early stopping\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eaeb8-bb05-48c0-a576-a2d479e8ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Dataset for emotion images organized in folders by class\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c130c-4a9c-4b8a-8610-339278ebb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_emotion_data(data_dir, val_split=0.2, random_state=42):\n",
    "    \"\"\"Load images from folder structure and create train/val split\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    all_paths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for emotion_name in CLASS_NAMES:\n",
    "        emotion_dir = data_dir / emotion_name\n",
    "        \n",
    "        if not emotion_dir.exists():\n",
    "            print(f\"Warning: Folder '{emotion_name}' not found in {data_dir}\")\n",
    "            continue\n",
    "        \n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif']:\n",
    "            image_files.extend(list(emotion_dir.glob(ext)))\n",
    "        \n",
    "        label_idx = CLASS_TO_IDX[emotion_name]\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            all_paths.append(str(img_path))\n",
    "            all_labels.append(label_idx)\n",
    "        \n",
    "        print(f\"Found {len(image_files)} images for '{emotion_name}'\")\n",
    "    \n",
    "    print(f\"Total images: {len(all_paths)}\")\n",
    "    \n",
    "    if val_split > 0:\n",
    "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "            all_paths, all_labels,\n",
    "            test_size=val_split,\n",
    "            random_state=random_state,\n",
    "            stratify=all_labels\n",
    "        )\n",
    "        print(f\"Train images: {len(train_paths)}\")\n",
    "        print(f\"Validation images: {len(val_paths)}\")\n",
    "        return train_paths, train_labels, val_paths, val_labels\n",
    "    else:\n",
    "        return all_paths, all_labels, [], []\n",
    "\n",
    "\n",
    "def get_data_loaders(train_dir, test_dir, batch_size=32, val_split=0.2, num_workers=4):\n",
    "    \"\"\"Create train, validation, and test data loaders\"\"\"\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    IMG_SIZE = 224\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # No augmentation for validation/test\n",
    "    val_test_transform = transforms.Compose([\n",
    "        transforms.Resize((48, 48)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    #Load training data (includes validataion data)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOADING TRAINING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    train_paths, train_labels, val_paths, val_labels = load_emotion_data(            #no random state?\n",
    "        train_dir, val_split=val_split\n",
    "    )\n",
    "\n",
    "    #Load test data\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LOADING TEST DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    test_paths, test_labels, _, _ = load_emotion_data(test_dir, val_split=0.0)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = EmotionDataset(train_paths, train_labels, transform=train_transform)\n",
    "    val_dataset = EmotionDataset(val_paths, val_labels, transform=val_test_transform)\n",
    "    test_dataset = EmotionDataset(test_paths, test_labels, transform=val_test_transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(                                   #DataLoader function defined in PyTorch. Returns images, labels in n=batchsize batches\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e02ad-5be8-4b72-8982-8e64c8a8cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL CREATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_resnet18_model(num_classes=7, pretrained=True):\n",
    "    \"\"\"Create ResNet-18 for emotion classification\"\"\"\n",
    "    \n",
    "    # Load pretrained weights or None\n",
    "    weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = resnet18(weights=weights)\n",
    "    \n",
    "    # Replace the classifier head with dropout + linear layer\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    # Set up for unfreezing only the final classification layer (Fast, change if need better performance)\n",
    "    # Freeze all backbone layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False   # <--- typo fixed\n",
    "    \n",
    "    # Unfreeze ONLY the final classification layer\n",
    "    model.fc[1].weight.requires_grad = True\n",
    "    model.fc[1].bias.requires_grad = True\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca5c6-c17b-4384-8ed2-fe861fa1d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):     #criterion = the loss function (e.g. nn.CrossEntropyLoss)\n",
    "    \"\"\"Train for one epoch\"\"\"                                               #optimizer updates the model's parameters (torch.optim.Adam or SGD)\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')         #pbar = progress bar -- for visualization\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)    #Moves tensors to GPU or CPU\n",
    "        \n",
    "        optimizer.zero_grad()                          #Before computing gradients for this batch, we reset previous gradients to zero.\n",
    "        \n",
    "        outputs = model(images)                         #feeds batch of images throught the network. Outputs tensor of shape (batch_size, num_classes),\n",
    "                                                        #   each row containing raw logits (unnormalized scores) for each class\n",
    "        loss = criterion(outputs, labels)               #Computes loss, returns scalar loss (average over the batch)\n",
    "        loss.backward()                                 #Back propagation\n",
    "        optimizer.step()                                #Uses the gradients to update the model's parameters (adjusts weights to reduce loss)\n",
    "        \n",
    "        # Update loss\n",
    "        running_loss += loss.item()                    #loss.item() converts the PyTorch scalar tensor to a Python float.\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update accuracy\n",
    "        _, predicted = outputs.max(1)                   #predicted gets the index of the maximum (argmax), i.e., the predicted class ID.\n",
    "        total += labels.size(0)                         #We increase total to track how many samples we've seen so far in the epoch.\n",
    "        correct += predicted.eq(labels).sum().item()    #correct = total number of correctly classified samples\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': running_loss / num_batches,\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / num_batches            #computes mean loss per batch\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc                       #Scalars: epoch_loss: average training loss for this epoch.\n",
    "                                                       #         epoch_acc: average training accuracy (percent).\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()                                       #Puts model in evaluation mode (turns off Dropout and uses running means instaed of batch stats)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():                                           #Pytorch does not compute gradients (optimizes performance & memory), avoids backdrop storage overhead\n",
    "        for images, labels in tqdm(val_loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                scheduler, device, num_epochs=50, patience=7):\n",
    "    \"\"\"Main training loop with early stopping\"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)                              \n",
    "        current_lr = optimizer.param_groups[0]['lr']          #grabs current learning rate from optimizer to print it\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'✓ New best model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'No improvement. Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\n⚠ Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)        # FIXME make sure plot_training_history is defined\n",
    "\n",
    "    #If you want to return best model, and not just the latest:\n",
    "    #model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    \n",
    "    return model, best_val_acc                                                   #returns model:FIXME current model(wights from last epoch trained, \n",
    "                                                                                #   not necessarily the best. (OK?) and returns best validation acc encountered \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c9761-01ed-40b6-81a3-00742256c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax1.plot(train_losses, label='Train Loss', marker='o')\n",
    "    ax1.plot(val_losses, label='Val Loss', marker='s')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax2.plot(train_accs, label='Train Acc', marker='o')\n",
    "    ax2.plot(val_accs, label='Val Acc', marker='s')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n✓ Training history plot saved as 'training_history.png'\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix', fontsize=16, pad=20)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"✓ Confusion matrix saved as 'confusion_matrix.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d0780-266a-4170-9bb1-0812a8463145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    \"\"\"Evaluate model on test set and plot confusion matrix.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            # Accumulate predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Accuracy update\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_acc = 100.0 * correct / total\n",
    "    print(f\"\\n✓ Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "    \n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14e246-5c7b-4473-820a-f4710f65dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FACIAL EMOTION RECOGNITION - ResNet18\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "    print(f\"Number of Epochs: {NUM_EPOCHS}\")\n",
    "    print(f\"Validation Split: {VAL_SPLIT}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load data\n",
    "    train_loader, val_loader, test_loader = get_data_loaders(\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        val_split=VAL_SPLIT,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData loaders ready:\")\n",
    "    print(f\"  Train batches: {len(train_loader)}\")\n",
    "    print(f\"  Val batches: {len(val_loader)}\")\n",
    "    print(f\"  Test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"INITIALIZING MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    model = create_resnet18_model(num_classes=len(CLASS_NAMES), pretrained=True)\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"✓ ResNet-18 model created (pretrained on ImageNet)\")\n",
    "    print(f\"✓ Final layer modified for {len(CLASS_NAMES)} classes\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    #Because we froze the backbone of the model and unfroze only the classification head, use the following optimizer instead:\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr = LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model, best_val_acc = train_model(\n",
    "        model, train_loader, val_loader, criterion, \n",
    "        optimizer, scheduler, DEVICE, \n",
    "        num_epochs=NUM_EPOCHS, patience=PATIENCE\n",
    "    )\n",
    "    \n",
    "    # Load best model for testing\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"LOADING BEST MODEL FOR TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    state_dict = torch.load('best_model.pth', map_location=DEVICE)        #ensures always load to correct device\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)                                                      #not necessary, ensures model is loaded to proper device\n",
    "    print(f\"✓ Loaded best model (Val Acc: {best_val_acc:.2f}%)\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_acc = evaluate_model(model, test_loader, DEVICE, CLASS_NAMES)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"Model saved as: best_model.pth\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fer2013)",
   "language": "python",
   "name": "fer2013env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
